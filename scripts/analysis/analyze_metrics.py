#!/usr/bin/env python3
"""
Aggregate MENACE experiment metrics.

This utility walks `menace_data/` (or a supplied root directory), parses the
`metrics.jsonl` files emitted by the training pipeline, and computes baseline
statistics:

* Total games, win/draw/loss rates from the agent's perspective
* Game index of the first agent win / first draw (sample-efficiency proxy)
* Simple aggregates (mean / standard deviation) across seeds for each condition
* Optional JSON export for downstream analysis

Run example:

    python -m scripts.analysis.analyze_metrics --experiments Pure_AIF_Beta_Sweep QL_vs_Defensive
"""

from __future__ import annotations

import argparse
import json
import statistics
from dataclasses import asdict, dataclass
from pathlib import Path
from typing import Dict, Iterable, List, Optional, Sequence, Tuple

# Default location generated by experiment_driver.py
DEFAULT_DATA_ROOT = Path("menace_data")


@dataclass
class RunStats:
    experiment: str
    condition: str
    seed: str
    games: int
    wins: int
    draws: int
    losses: int
    games_to_first_win: Optional[int]
    games_to_first_draw: Optional[int]

    @property
    def win_rate(self) -> float:
        return self.wins / self.games if self.games else 0.0

    @property
    def draw_rate(self) -> float:
        return self.draws / self.games if self.games else 0.0

    @property
    def loss_rate(self) -> float:
        return self.losses / self.games if self.games else 0.0


@dataclass
class ConditionAggregate:
    experiment: str
    condition: str
    seeds: int
    win_rate_mean: float
    win_rate_std: Optional[float]
    draw_rate_mean: float
    draw_rate_std: Optional[float]
    loss_rate_mean: float
    loss_rate_std: Optional[float]
    games_to_first_win_mean: Optional[float]
    games_to_first_win_std: Optional[float]
    games_to_first_draw_mean: Optional[float]
    games_to_first_draw_std: Optional[float]


def iter_metrics_files(root: Path) -> Iterable[Tuple[str, str, Path]]:
    """
    Yields (experiment_name, condition_name, path) tuples for all metrics.jsonl files.
    Two layouts are supported:
      root/Experiment/condition/seed_x/metrics.jsonl
      root/Experiment/seed_x/metrics.jsonl
    """
    if not root.exists():
        raise FileNotFoundError(f"Metrics root directory not found: {root}")

    for experiment_dir in sorted(p for p in root.iterdir() if p.is_dir()):
        experiment = experiment_dir.name
        for condition_dir in sorted(experiment_dir.iterdir()):
            if condition_dir.is_file():
                continue
            # Condition directory contains seeds or is itself a seed directory
            if condition_dir.name.startswith("seed_"):
                metrics = condition_dir / "metrics.jsonl"
                if metrics.exists():
                    yield experiment, "default", metrics
                continue

            condition = condition_dir.name
            for seed_dir in sorted(condition_dir.iterdir()):
                if not seed_dir.is_dir() or not seed_dir.name.startswith("seed_"):
                    continue
                metrics = seed_dir / "metrics.jsonl"
                if metrics.exists():
                    yield experiment, condition, metrics


def parse_run_stats(
    experiment: str, condition: str, metrics_path: Path
) -> Optional[RunStats]:
    """Read a metrics.jsonl file and compute per-run statistics."""
    wins = draws = losses = 0
    games_to_first_win = None
    games_to_first_draw = None

    try:
        with metrics_path.open("r", encoding="utf-8") as handle:
            for index, line in enumerate(handle):
                line = line.strip()
                if not line:
                    continue
                record = json.loads(line)
                outcome: str = record.get("outcome", "")
                if outcome.startswith("Win(X)"):
                    wins += 1
                    if games_to_first_win is None:
                        games_to_first_win = index
                elif outcome == "Draw":
                    draws += 1
                    if games_to_first_draw is None:
                        games_to_first_draw = index
                elif outcome.startswith("Win(O)"):
                    losses += 1
                else:
                    raise ValueError(
                        f"Unexpected outcome '{outcome}' in {metrics_path} (record {index})"
                    )
    except json.JSONDecodeError as err:
        raise ValueError(f"Invalid JSON in {metrics_path}: {err}") from err

    total_games = wins + draws + losses
    if total_games == 0:
        return None

    seed = metrics_path.parent.name
    # convert 0-based indices to counts (games played before first success)
    if games_to_first_win is not None:
        games_to_first_win += 1
    if games_to_first_draw is not None:
        games_to_first_draw += 1

    return RunStats(
        experiment=experiment,
        condition=condition,
        seed=seed,
        games=total_games,
        wins=wins,
        draws=draws,
        losses=losses,
        games_to_first_win=games_to_first_win,
        games_to_first_draw=games_to_first_draw,
    )


def aggregate_condition(run_stats: Sequence[RunStats]) -> ConditionAggregate:
    """Compute aggregate statistics across seeds for a condition."""
    if not run_stats:
        raise ValueError("aggregate_condition() received an empty run_stats list")

    experiment = run_stats[0].experiment
    condition = run_stats[0].condition

    win_rates = [r.win_rate for r in run_stats]
    draw_rates = [r.draw_rate for r in run_stats]
    loss_rates = [r.loss_rate for r in run_stats]
    first_win = [
        r.games_to_first_win for r in run_stats if r.games_to_first_win is not None
    ]
    first_draw = [
        r.games_to_first_draw for r in run_stats if r.games_to_first_draw is not None
    ]

    def mean(values: Sequence[float]) -> float:
        return float(statistics.mean(values)) if values else 0.0

    def std(values: Sequence[float]) -> Optional[float]:
        if len(values) < 2:
            return None
        return float(statistics.stdev(values))

    return ConditionAggregate(
        experiment=experiment,
        condition=condition,
        seeds=len(run_stats),
        win_rate_mean=mean(win_rates),
        win_rate_std=std(win_rates),
        draw_rate_mean=mean(draw_rates),
        draw_rate_std=std(draw_rates),
        loss_rate_mean=mean(loss_rates),
        loss_rate_std=std(loss_rates),
        games_to_first_win_mean=mean(first_win) if first_win else None,
        games_to_first_win_std=std(first_win) if len(first_win) >= 2 else None,
        games_to_first_draw_mean=mean(first_draw) if first_draw else None,
        games_to_first_draw_std=std(first_draw) if len(first_draw) >= 2 else None,
    )


def collate_stats(
    data_root: Path,
    experiments: Optional[Sequence[str]] = None,
) -> Tuple[List[RunStats], List[ConditionAggregate]]:
    """Collect run-level and aggregate statistics."""
    selected = set(experiments) if experiments else None
    run_entries: List[RunStats] = []
    by_condition: Dict[Tuple[str, str], List[RunStats]] = {}

    for experiment, condition, metrics in iter_metrics_files(data_root):
        if selected and experiment not in selected:
            continue
        run = parse_run_stats(experiment, condition, metrics)
        if run is None:
            continue
        run_entries.append(run)
        by_condition.setdefault((experiment, condition), []).append(run)

    aggregates = [aggregate_condition(runs) for runs in by_condition.values() if runs]
    aggregates.sort(key=lambda agg: (agg.experiment, agg.condition))
    return run_entries, aggregates


def format_percentage(value: float) -> str:
    return f"{value * 100:.2f}%"


def print_summary(aggregates: Sequence[ConditionAggregate]) -> None:
    if not aggregates:
        print("No experiment data found.")
        return

    current_experiment = None
    for agg in aggregates:
        if agg.experiment != current_experiment:
            current_experiment = agg.experiment
            print("\n" + "=" * 80)
            print(current_experiment)
            print("=" * 80)

        print(f"\nCondition: {agg.condition}  (seeds: {agg.seeds})")
        win_line = f"Win rate : {format_percentage(agg.win_rate_mean)}"
        if agg.win_rate_std is not None:
            win_line += f" ± {agg.win_rate_std * 100:.2f}%"
        print(win_line)

        draw_line = f"Draw rate: {format_percentage(agg.draw_rate_mean)}"
        if agg.draw_rate_std is not None:
            draw_line += f" ± {agg.draw_rate_std * 100:.2f}%"
        print(draw_line)

        loss_line = f"Loss rate: {format_percentage(agg.loss_rate_mean)}"
        if agg.loss_rate_std is not None:
            loss_line += f" ± {agg.loss_rate_std * 100:.2f}%"
        print(loss_line)

        if agg.games_to_first_draw_mean is not None:
            print(
                f"Games to first draw: {agg.games_to_first_draw_mean:.2f}"
                + (
                    f" ± {agg.games_to_first_draw_std:.2f}"
                    if agg.games_to_first_draw_std is not None
                    else ""
                )
            )
        if agg.games_to_first_win_mean is not None:
            print(
                f"Games to first win : {agg.games_to_first_win_mean:.2f}"
                + (
                    f" ± {agg.games_to_first_win_std:.2f}"
                    if agg.games_to_first_win_std is not None
                    else ""
                )
            )


def main() -> None:
    parser = argparse.ArgumentParser(description="Aggregate MENACE experiment metrics.")
    parser.add_argument(
        "--root",
        type=Path,
        default=DEFAULT_DATA_ROOT,
        help=f"Root directory containing experiment data (default: {DEFAULT_DATA_ROOT})",
    )
    parser.add_argument(
        "--experiments",
        nargs="*",
        help="Optional list of experiment directories to include.",
    )
    parser.add_argument(
        "--output",
        type=Path,
        help="Optional path to write aggregated statistics as JSON.",
    )
    args = parser.parse_args()

    run_stats, aggregates = collate_stats(args.root, args.experiments)
    print_summary(aggregates)

    if args.output:
        output_payload = {
            "runs": [asdict(run) for run in run_stats],
            "aggregates": [asdict(agg) for agg in aggregates],
        }
        args.output.parent.mkdir(parents=True, exist_ok=True)
        with args.output.open("w", encoding="utf-8") as handle:
            json.dump(output_payload, handle, indent=2)
        print(f"\nWrote aggregated statistics to {args.output}")


if __name__ == "__main__":
    main()
