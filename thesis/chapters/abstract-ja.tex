自由エネルギー原理（FEP）に基づく能動的推論は，知覚，学習，行動に対する統一的な目的関数を提供する．しかし，その説明範囲の広さにもかかわらず，明示的な期待自由エネルギー目標によって明確に駆動されるエンドツーエンドの計算エージェントは，完全に列挙可能なドメインにおいても構築および検証が困難である．本論文では，Donald Michieが考案したMENACE（三目並べのための解釈可能なマッチボックスとビーズによる学習器）を，動作する学習メカニズムと能動的推論の解釈をつなぐ具体的で完全に分析可能な橋渡しとして使用する．

MENACEの287個のマッチボックスとビーズ更新をディリクレ・カテゴリカルモデルに対応付ける：ビーズの数はディリクレの擬似カウントとして機能し，ランダムなビーズの抽出は事後予測確率マッチングを実装する．明示的なモデリングの下で，MENACEは期待自由エネルギー最小化の道具的な特殊ケース（$\lambda = 0$）に対応し，能動的推論の変種は相互情報量$I(o;\theta)$を通じて認識論的価値を導入する．次に，制御されたカリキュラムと最適プレイに対する評価の下で，能動的推論の変種およびテーブル型強化学習ベースラインに対して経験的に対応関係を検証する．

結果は，この設定における探索と活用のトレードオフを定量化する：MENACEの探索圧力はディリクレ濃度が増加するにつれて内生的に減衰するのに対し，固定された認識論的重み$\lambda$はトレードオフ係数のみを固定する（認識論的項自体は通常，事後濃度とともに減少する）．より広い状態行動カバレッジとより大きな予算があれば，テーブル型RLもミニマックス性能に近づくことができ，主要な違いはサンプル効率，対戦相手分布感度，および解釈可能性であり，漸近的能力ではないことを強調する．能動的推論を機械的に実装可能なシステムに基盤づけることにより，本論文はFEPに関する方法論的議論の具体的なテストケースを提供し，MENACEのどの側面が能動的推論によって説明され，どの側面が追加の仮定を必要とするかを明確にする．
