Active Inference under the Free Energy Principle (FEP) provides a unified objective for perception, learning, and action. Yet, despite its explanatory scope, end-to-end computational agents that are clearly driven by an explicit expected free energy objective remain difficult to build and to validate in fully enumerable domains. This thesis uses Donald Michie's MENACE---an interpretable matchbox-and-bead learner for Tic-Tac-Toe---as a concrete, fully analysable bridge between a working learning mechanism and an Active Inference interpretation.

We map MENACE's 287 matchboxes and bead updates to a Dirichletâ€“categorical model: bead counts act as Dirichlet pseudo-counts and random bead draws implement posterior predictive probability matching. Under explicit modelling commitments, MENACE corresponds to an instrumental special case of expected free energy minimisation ($\lambda = 0$), while Active Inference variants introduce epistemic value via the mutual information $I(o;\theta)$. We then test the correspondence empirically against Active Inference variants and tabular reinforcement learning baselines under controlled curricula and evaluation against optimal play.

The results quantify the exploration--exploitation trade-off in this setting: MENACE's exploration pressure decays endogenously as Dirichlet concentration increases, whereas a fixed epistemic weight $\lambda$ fixes only a trade-off coefficient (the epistemic term itself typically diminishes with posterior concentration). With broader state-action coverage and a larger budget, tabular RL can also approach minimax performance, highlighting that the key differences are sample efficiency, opponent-distribution sensitivity, and interpretability rather than asymptotic capability. By grounding Active Inference in a mechanically implementable system, the thesis provides a concrete test case for methodological debates about the FEP and clarifies which aspects of MENACE are explained by Active Inference and which require additional assumptions.
